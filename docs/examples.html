<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Examples - Stable Request</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>‚ö°</text></svg>">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <link rel="stylesheet" href="styles.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/typescript.min.js"></script>
</head>
<body>
    <nav class="navbar">
        <div class="container">
            <a href="index.html" class="nav-brand">
                <span class="logo">‚ö°</span>
                <span class="brand-name">Stable Request</span>
            </a>
            <div class="nav-links">
                <a href="index.html">Home</a>
                <a href="documentation.html">Documentation</a>
                <a href="examples.html" class="active">Examples</a>
                <a href="https://github.com/Emmvish/stable-request" target="_blank">GitHub</a>
            </div>
        </div>
    </nav>

    <div class="examples-hero">
        <div class="container">
            <h1>Production-Ready Examples</h1>
            <p>Real-world use cases demonstrating the power of stable-request</p>
        </div>
    </div>

    <div class="container examples-content">
        <div class="example-showcase">
            <div class="example-item">
                <div class="example-header">
                    <span class="example-number">01</span>
                    <h2>Multi-Source Data Synchronization Pipeline</h2>
                    <div class="example-tags">
                        <span class="tag">Non-Linear Workflow</span>
                        <span class="tag">Circuit Breaker</span>
                        <span class="tag">Caching</span>
                        <span class="tag">Rate Limiting</span>
                    </div>
                </div>
                
                <div class="example-description">
                    <p>A comprehensive data synchronization workflow that fetches data from multiple API endpoints, validates and transforms it, then uploads to an internal system with full observability.</p>
                    
                    <h4>Key Features:</h4>
                    <ul>
                        <li>‚úÖ Multi-phase workflow orchestration</li>
                        <li>‚úÖ Concurrent data fetching from multiple sources</li>
                        <li>‚úÖ Phase decision hooks with REPLAY action</li>
                        <li>‚úÖ Circuit breaker integration</li>
                        <li>‚úÖ Response caching with TTL</li>
                        <li>‚úÖ Rate limiting (50 requests per 10 seconds)</li>
                        <li>‚úÖ Exponential backoff retry strategy</li>
                        <li>‚úÖ Pre-execution hooks for data enrichment</li>
                        <li>‚úÖ Shared buffer for cross-phase state management</li>
                    </ul>
                    
                    <h4>Use Case:</h4>
                    <p>Enterprise data synchronization from external APIs with validation, transformation, and batch uploading.</p>
                </div>
                
                <div class="example-code">
                    <div class="example-actions">
                        <button class="btn btn-primary run-example-btn" data-example="01">
                            ‚ñ∂ Run Example
                        </button>
                        <button class="btn btn-secondary clear-output-btn" data-example="01" style="display:none;">
                            Clear Output
                        </button>
                    </div>
                    <div class="example-output" id="output-01" style="display:none;"></div>
                    <h4>Complete Working Example</h4>
                    <pre><code class="language-typescript">import { 
  stableWorkflow, 
  RETRY_STRATEGIES, 
  PHASE_DECISION_ACTIONS,
  REQUEST_METHODS,
  VALID_REQUEST_PROTOCOLS,
  type STABLE_WORKFLOW_PHASE
} from '@emmvish/stable-request';

// Shared state for workflow
interface SyncState {
  syncId: string;
  startTime: number;
  users: any[];
  posts: any[];
  comments: any[];
  enrichedData: any[];
  validationErrors: string[];
  uploadedRecords: number;
  failedRecords: number;
  retryCount: number;
}

const syncState: SyncState = {
  syncId: `sync-${Date.now()}`,
  startTime: Date.now(),
  users: [],
  posts: [],
  comments: [],
  enrichedData: [],
  validationErrors: [],
  uploadedRecords: 0,
  failedRecords: 0,
  retryCount: 0
};

// Circuit breaker configuration for source API
const sourceApiBreaker = {
  failureThresholdPercentage: 50,
  minimumRequests: 3,
  recoveryTimeoutMs: 30000,
  successThresholdPercentage: 60,
  halfOpenMaxRequests: 2,
  trackIndividualAttempts: false
};

// Define the multi-phase workflow
const syncPhases: STABLE_WORKFLOW_PHASE[] = [
  // Phase 1: Fetch data from multiple sources concurrently
  {
    id: 'fetch-source-data',
    concurrentExecution: true,
    requests: [
      {
        id: 'fetch-users',
        requestOptions: {
          reqData: { 
            path: '/users?_limit=5',
            method: REQUEST_METHODS.GET
          },
          resReq: true,
          handleSuccessfulAttemptData: async ({ successfulAttemptData, commonBuffer }) => {
            const buffer = commonBuffer as SyncState;
            buffer.users = successfulAttemptData.data;
            console.log(`‚úÖ Fetched ${buffer.users.length} users`);
          }
        }
      },
      {
        id: 'fetch-posts',
        requestOptions: {
          reqData: { 
            path: '/posts?_limit=10',
            method: REQUEST_METHODS.GET
          },
          resReq: true,
          handleSuccessfulAttemptData: async ({ successfulAttemptData, commonBuffer }) => {
            const buffer = commonBuffer as SyncState;
            buffer.posts = successfulAttemptData.data;
            console.log(`‚úÖ Fetched ${buffer.posts.length} posts`);
          }
        }
      },
      {
        id: 'fetch-comments',
        requestOptions: {
          reqData: { 
            path: '/comments?_limit=20',
            method: REQUEST_METHODS.GET
          },
          resReq: true,
          handleSuccessfulAttemptData: async ({ successfulAttemptData, commonBuffer }) => {
            const buffer = commonBuffer as SyncState;
            buffer.comments = successfulAttemptData.data;
            console.log(`‚úÖ Fetched ${buffer.comments.length} comments`);
          }
        }
      }
    ]
  },

  // Phase 2: Data enrichment and transformation
  {
    id: 'enrich-data',
    requests: [
      {
        id: 'enrich-posts-with-users',
        requestOptions: {
          reqData: { path: '/posts/1', method: REQUEST_METHODS.GET },
          resReq: false,
          preExecution: {
            preExecutionHook: ({ commonBuffer }) => {
              const buffer = commonBuffer as SyncState;
              
              // Enrich posts with user information
              buffer.enrichedData = buffer.posts.map(post => {
                const user = buffer.users.find(u => u.id === post.userId);
                const postComments = buffer.comments.filter(c => c.postId === post.id);
                
                return {
                  postId: post.id,
                  title: post.title,
                  body: post.body,
                  author: user ? {
                    id: user.id,
                    name: user.name,
                    email: user.email,
                    company: user.company?.name
                  } : null,
                  commentCount: postComments.length,
                  enrichedAt: new Date().toISOString(),
                  syncId: buffer.syncId
                };
              });
              
              console.log(`‚úÖ Enriched ${buffer.enrichedData.length} posts`);
              return {};
            },
            applyPreExecutionConfigOverride: false
          }
        }
      }
    ]
  },

  // Phase 3: Data validation with conditional retry
  {
    id: 'validate-data',
    allowReplay: true,
    maxReplayCount: 2,
    requests: [
      {
        id: 'validate-enriched-data',
        requestOptions: {
          reqData: { path: '/posts/1', method: REQUEST_METHODS.GET },
          resReq: false,
          preExecution: {
            preExecutionHook: ({ commonBuffer }) => {
              const buffer = commonBuffer as SyncState;
              buffer.validationErrors = [];
              
              // Validate enriched data
              buffer.enrichedData.forEach((item, index) => {
                if (!item.author) {
                  buffer.validationErrors.push(`Record ${index}: Missing author`);
                }
                if (!item.title || item.title.length < 5) {
                  buffer.validationErrors.push(`Record ${index}: Invalid title`);
                }
              });
              
              console.log(`‚úÖ Validation complete: ${buffer.validationErrors.length} errors`);
              return {};
            },
            applyPreExecutionConfigOverride: false
          }
        }
      }
    ],
    phaseDecisionHook: async ({ phaseResult, sharedBuffer }) => {
      const buffer = sharedBuffer as SyncState;
      
      if (buffer.validationErrors.length > 0 && buffer.retryCount < 2) {
        buffer.retryCount++;
        console.log(`‚ö†Ô∏è  Validation errors found, retrying...`);
        return { action: PHASE_DECISION_ACTIONS.REPLAY };
      }
      
      console.log(`‚úÖ Validation passed, proceeding...`);
      return { action: PHASE_DECISION_ACTIONS.CONTINUE };
    }
  },

  // Phase 4: Batch upload
  {
    id: 'upload-data',
    concurrentExecution: true,
    requests: [] // Will be populated dynamically
  }
];

// Execute workflow
const result = await stableWorkflow(syncPhases, {
  workflowId: 'data-sync-pipeline',
  commonRequestData: { 
    hostname: 'jsonplaceholder.typicode.com',
    protocol: VALID_REQUEST_PROTOCOLS.HTTPS
  },
  commonAttempts: 3,
  commonWait: 1000,
  commonRetryStrategy: RETRY_STRATEGIES.EXPONENTIAL,
  enableNonLinearExecution: true,
  circuitBreaker: sourceApiBreaker,
  commonCache: { ttl: 300000, enabled: true },
  rateLimit: { maxRequests: 50, windowMs: 10000 },
  sharedBuffer: syncState,
  handlePhaseCompletion: async ({ phaseResult }) => {
    console.log(`‚úÖ Phase ${phaseResult.phaseId} completed in ${phaseResult.executionTime}ms`);
  }
});

console.log(`\nüìä Workflow Results:`);
console.log(`Total Phases: ${result.totalPhases}`);
console.log(`Success: ${result.success}`);
console.log(`Duration: ${result.executionTime}ms`);</code></pre>
                </div>
            </div>

            <div class="example-item">
                <div class="example-header">
                    <span class="example-number">02</span>
                    <h2>Resilient Microservice Orchestration</h2>
                    <div class="example-tags">
                        <span class="tag">Branched Workflows</span>
                        <span class="tag">Circuit Breakers</span>
                        <span class="tag">Request Grouping</span>
                        <span class="tag">Fallback Strategies</span>
                    </div>
                </div>
                
                <div class="example-description">
                    <p>A sophisticated microservice orchestration pattern coordinating user validation, inventory management, payment processing, and notifications with proper failure handling.</p>
                    
                    <h4>Key Features:</h4>
                    <ul>
                        <li>‚úÖ Branch workflow execution</li>
                        <li>‚úÖ Mixed concurrent and sequential branches</li>
                        <li>‚úÖ Multiple circuit breakers (one per service)</li>
                        <li>‚úÖ Request grouping with different retry policies</li>
                        <li>‚úÖ Branch decision hooks (REPLAY and TERMINATE actions)</li>
                        <li>‚úÖ Workflow termination on critical failures</li>
                        <li>‚úÖ Graceful handling of non-critical failures</li>
                        <li>‚úÖ Complex state management across branches</li>
                    </ul>
                    
                    <h4>Use Case:</h4>
                    <p>E-commerce order processing coordinating multiple microservices with isolated failure handling and proper SLA requirements.</p>
                </div>
                
                <div class="example-code">
                    <div class="example-actions">
                        <button class="btn btn-primary run-example-btn" data-example="02">
                            ‚ñ∂ Run Example
                        </button>
                        <button class="btn btn-secondary clear-output-btn" data-example="02" style="display:none;">
                            Clear Output
                        </button>
                    </div>
                    <div class="example-output" id="output-02" style="display:none;"></div>
                    <h4>Complete Working Example</h4>
                    <pre><code class="language-typescript">import { 
  stableWorkflow, 
  RETRY_STRATEGIES, 
  PHASE_DECISION_ACTIONS,
  CircuitBreaker,
  REQUEST_METHODS,
  type STABLE_WORKFLOW_BRANCH
} from '@emmvish/stable-request';

// Order processing state
interface OrderContext {
  orderId: string;
  customerId: number;
  items: Array<{ productId: number; quantity: number; price: number }>;
  totalAmount: number;
  customerData?: any;
  inventoryCheck?: { available: boolean; reservationId?: string };
  paymentResult?: { success: boolean; transactionId?: string };
  notificationsSent?: string[];
  startTime: number;
  retryAttempts: {
    payment: number;
    inventory: number;
    notification: number;
  };
  serviceFailures: {
    userService: number;
    inventoryService: number;
    paymentService: number;
    notificationService: number;
  };
  fallbacksUsed: string[];
}

const orderContext: OrderContext = {
  orderId: `ORD-${Date.now()}`,
  customerId: 1,
  items: [
    { productId: 1, quantity: 2, price: 29.99 },
    { productId: 2, quantity: 1, price: 49.99 }
  ],
  totalAmount: 109.97,
  startTime: Date.now(),
  retryAttempts: { payment: 0, inventory: 0, notification: 0 },
  serviceFailures: {
    userService: 0,
    inventoryService: 0,
    paymentService: 0,
    notificationService: 0
  },
  fallbacksUsed: [],
  notificationsSent: []
};

// Circuit breakers for each microservice
const circuitBreakers = {
  userService: new CircuitBreaker({
    failureThresholdPercentage: 60,
    minimumRequests: 2,
    recoveryTimeoutMs: 20000,
    successThresholdPercentage: 50,
    halfOpenMaxRequests: 1
  }),
  inventoryService: new CircuitBreaker({
    failureThresholdPercentage: 50,
    minimumRequests: 2,
    recoveryTimeoutMs: 30000,
    successThresholdPercentage: 60,
    halfOpenMaxRequests: 2
  }),
  paymentService: new CircuitBreaker({
    failureThresholdPercentage: 40,
    minimumRequests: 2,
    recoveryTimeoutMs: 45000,
    successThresholdPercentage: 70,
    halfOpenMaxRequests: 1
  }),
  notificationService: new CircuitBreaker({
    failureThresholdPercentage: 70,
    minimumRequests: 3,
    recoveryTimeoutMs: 15000,
    successThresholdPercentage: 50,
    halfOpenMaxRequests: 3
  })
};

// Define the branched workflow
const orderBranches: STABLE_WORKFLOW_BRANCH[] = [
  // Branch 1: User Validation (Critical)
  {
    id: 'user-validation',
    markConcurrentBranch: false,
    phases: [
      {
        id: 'fetch-user-details',
        requests: [
          {
            id: 'get-user',
            groupId: 'critical',
            requestOptions: {
              reqData: {
                path: `/users/${orderContext.customerId}`,
                method: REQUEST_METHODS.GET
              },
              resReq: true,
              circuitBreaker: circuitBreakers.userService,
              handleSuccessfulAttemptData: async ({ successfulAttemptData, commonBuffer }) => {
                const buffer = commonBuffer as OrderContext;
                buffer.customerData = successfulAttemptData.data;
                console.log(`‚úÖ Customer validated: ${buffer.customerData.name}`);
              },
              handleErrors: async ({ errorLog, commonBuffer }) => {
                const buffer = commonBuffer as OrderContext;
                buffer.serviceFailures.userService++;
                console.log(`‚ö†Ô∏è  User Service attempt failed`);
              }
            }
          }
        ]
      },
      {
        id: 'verify-user-status',
        requests: [
          {
            id: 'check-user-status',
            groupId: 'critical',
            requestOptions: {
              reqData: {
                path: `/users/${orderContext.customerId}/todos?_limit=1`,
                method: REQUEST_METHODS.GET
              },
              resReq: false,
              preExecution: {
                preExecutionHook: ({ commonBuffer }) => {
                  const buffer = commonBuffer as OrderContext;
                  console.log(`‚úÖ Account status verified for ${buffer.customerData?.name}`);
                  return {};
                },
                applyPreExecutionConfigOverride: false,
                continueOnPreExecutionHookFailure: false
              }
            }
          }
        ]
      }
    ]
  },

  // Branch 2: Inventory Management (Critical with fallback)
  {
    id: 'inventory-management',
    markConcurrentBranch: true,
    allowReplay: true,
    maxReplayCount: 2,
    phases: [
      {
        id: 'check-inventory',
        requests: [
          {
            id: 'verify-stock',
            groupId: 'critical',
            requestOptions: {
              reqData: {
                path: '/posts?_limit=5',
                method: REQUEST_METHODS.GET
              },
              resReq: true,
              circuitBreaker: circuitBreakers.inventoryService,
              handleSuccessfulAttemptData: async ({ successfulAttemptData, commonBuffer }) => {
                const buffer = commonBuffer as OrderContext;
                buffer.inventoryCheck = {
                  available: true,
                  reservationId: `RES-${Date.now()}`
                };
                console.log(`‚úÖ Inventory available, reserved: ${buffer.inventoryCheck.reservationId}`);
              }
            }
          }
        ]
      }
    ],
    branchDecisionHook: async ({ branchResult, sharedBuffer }) => {
      const buffer = sharedBuffer as OrderContext;
      
      if (!branchResult.success && buffer.retryAttempts.inventory < 2) {
        buffer.retryAttempts.inventory++;
        console.log(`üîÑ Retrying inventory check (attempt ${buffer.retryAttempts.inventory})...`);
        return { action: PHASE_DECISION_ACTIONS.REPLAY };
      }
      
      if (!branchResult.success) {
        console.log(`‚ùå Inventory check failed after retries`);
        return { action: PHASE_DECISION_ACTIONS.TERMINATE };
      }
      
      return { action: PHASE_DECISION_ACTIONS.CONTINUE };
    }
  },

  // Branch 3: Payment Processing (Critical)
  {
    id: 'payment-processing',
    markConcurrentBranch: true,
    phases: [
      {
        id: 'authorize-payment',
        requests: [
          {
            id: 'process-payment',
            groupId: 'critical',
            requestOptions: {
              reqData: {
                path: '/posts/1',
                method: REQUEST_METHODS.GET
              },
              resReq: true,
              circuitBreaker: circuitBreakers.paymentService,
              handleSuccessfulAttemptData: async ({ successfulAttemptData, commonBuffer }) => {
                const buffer = commonBuffer as OrderContext;
                buffer.paymentResult = {
                  success: true,
                  transactionId: `TXN-${Date.now()}`
                };
                console.log(`‚úÖ Payment processed: ${buffer.paymentResult.transactionId}`);
              }
            }
          }
        ]
      }
    ]
  },

  // Branch 4: Notification Service (Optional)
  {
    id: 'notification-service',
    markConcurrentBranch: true,
    phases: [
      {
        id: 'send-notifications',
        requests: [
          {
            id: 'email-notification',
            groupId: 'optional',
            requestOptions: {
              reqData: {
                path: '/comments/1',
                method: REQUEST_METHODS.GET
              },
              resReq: false,
              circuitBreaker: circuitBreakers.notificationService,
              preExecution: {
                preExecutionHook: ({ commonBuffer }) => {
                  const buffer = commonBuffer as OrderContext;
                  buffer.notificationsSent = ['email', 'sms'];
                  console.log(`‚úÖ Notifications sent to customer`);
                  return {};
                },
                applyPreExecutionConfigOverride: false
              }
            }
          }
        ]
      }
    ]
  }
];

// Execute branched workflow
const result = await stableWorkflow([], {
  workflowId: 'order-processing',
  commonRequestData: { 
    hostname: 'jsonplaceholder.typicode.com',
    protocol: 'https'
  },
  enableBranchExecution: true,
  branches: orderBranches,
  concurrentBranchExecution: true,
  requestGroups: [
    {
      id: 'critical',
      commonConfig: {
        commonAttempts: 5,
        commonWait: 1000,
        commonRetryStrategy: RETRY_STRATEGIES.EXPONENTIAL
      }
    },
    {
      id: 'optional',
      commonConfig: {
        commonAttempts: 1,
        commonWait: 500
      }
    }
  ],
  sharedBuffer: orderContext,
  handleBranchCompletion: async ({ branchId, success }) => {
    if (!success && branchId !== 'notification-service') {
      console.error(`‚ùå Critical branch ${branchId} failed`);
    }
  }
});

console.log(`\nüìä Order Processing Results:`);
console.log(`Success: ${result.success}`);
console.log(`Order ID: ${orderContext.orderId}`);
console.log(`Duration: ${result.executionTime}ms`);</code></pre>
                </div>
            </div>

            <div class="example-item">
                <div class="example-header">
                    <span class="example-number">03</span>
                    <h2>Production API Health Monitoring</h2>
                    <div class="example-tags">
                        <span class="tag">Health Checks</span>
                        <span class="tag">SLA Tracking</span>
                        <span class="tag">Alerting</span>
                        <span class="tag">Metrics</span>
                    </div>
                </div>
                
                <div class="example-description">
                    <p>A comprehensive health monitoring system that tracks service availability, response times, and SLA compliance with real-time alerting.</p>
                    
                    <h4>Key Features:</h4>
                    <ul>
                        <li>‚úÖ Individual service health checks with stableRequest</li>
                        <li>‚úÖ Circuit breaker per service</li>
                        <li>‚úÖ Exponential backoff retry strategy</li>
                        <li>‚úÖ Response caching with 5-second TTL</li>
                        <li>‚úÖ SLA threshold validation (200ms - 2000ms)</li>
                        <li>‚úÖ Consecutive failure tracking with alerting</li>
                        <li>‚úÖ Critical vs optional service differentiation</li>
                        <li>‚úÖ Real-time performance metrics</li>
                    </ul>
                    
                    <h4>Use Case:</h4>
                    <p>Production monitoring system tracking API health with automatic alerting on SLA breaches or consecutive failures.</p>
                </div>
                
                <div class="example-code">
                    <div class="example-actions">
                        <button class="btn btn-primary run-example-btn" data-example="03">
                            ‚ñ∂ Run Example
                        </button>
                        <button class="btn btn-secondary clear-output-btn" data-example="03" style="display:none;">
                            Clear Output
                        </button>
                    </div>
                    <div class="example-output" id="output-03" style="display:none;"></div>
                    <h4>Complete Working Example</h4>
                    <pre><code class="language-typescript">import { 
  stableRequest, 
  RETRY_STRATEGIES,
  CircuitBreaker,
  VALID_REQUEST_PROTOCOLS,
  REQUEST_METHODS
} from '@emmvish/stable-request';

// Service endpoint configuration
interface ServiceEndpoint {
  name: string;
  url: string;
  critical: boolean;
  slaThresholdMs: number;
  healthCheckPath: string;
}

interface HealthCheckResult {
  service: string;
  status: 'healthy' | 'degraded' | 'down';
  responseTime: number;
  timestamp: string;
  consecutiveFailures: number;
  circuitBreakerState: string;
  slaCompliant: boolean;
}

// Define monitored services
const services: ServiceEndpoint[] = [
  {
    name: 'User Authentication API',
    url: 'https://jsonplaceholder.typicode.com',
    critical: true,
    slaThresholdMs: 200,
    healthCheckPath: '/users/1'
  },
  {
    name: 'Payment Gateway',
    url: 'https://jsonplaceholder.typicode.com',
    critical: true,
    slaThresholdMs: 500,
    healthCheckPath: '/posts/1'
  },
  {
    name: 'Notification Service',
    url: 'https://jsonplaceholder.typicode.com',
    critical: false,
    slaThresholdMs: 1000,
    healthCheckPath: '/comments/1'
  }
];

// Initialize circuit breakers for each service
const circuitBreakers = new Map<string, CircuitBreaker>();
services.forEach(service => {
  circuitBreakers.set(service.name, new CircuitBreaker({
    failureThresholdPercentage: service.critical ? 50 : 70,
    minimumRequests: 3,
    recoveryTimeoutMs: service.critical ? 10000 : 20000,
    successThresholdPercentage: 60,
    halfOpenMaxRequests: 2
  }));
});

// Track consecutive failures per service
const failureTracker = new Map<string, number>();

// Perform health check using stableRequest
async function checkServiceHealth(service: ServiceEndpoint): Promise<HealthCheckResult> {
  const startTime = Date.now();
  const circuitBreaker = circuitBreakers.get(service.name)!;
  
  console.log(`üîç Checking ${service.name}...`);
  
  try {
    await stableRequest({
      reqData: {
        hostname: service.url.replace(/^https?:\/\//, ''),
        protocol: VALID_REQUEST_PROTOCOLS.HTTPS,
        path: service.healthCheckPath,
        method: REQUEST_METHODS.GET,
        headers: {
          'User-Agent': 'HealthMonitor/1.0',
          'Accept': 'application/json'
        },
        timeout: service.slaThresholdMs * 2
      },
      
      // Retry configuration based on criticality
      attempts: service.critical ? 3 : 2,
      wait: 1000,
      retryStrategy: RETRY_STRATEGIES.EXPONENTIAL,
      maxAllowedWait: 5000,
      
      // Circuit breaker to prevent cascade failures
      circuitBreaker: circuitBreaker,
      
      // Cache successful health checks (5 second TTL)
      cache: { ttl: 5000, enabled: true },
      
      // Response validation
      resReq: true,
      responseAnalyzer: ({ data }) => {
        return data && typeof data === 'object' && Object.keys(data).length > 0;
      },
      
      // Performance tracking
      handleSuccessfulAttemptData: async ({ successfulAttemptData }) => {
        const responseTime = successfulAttemptData.executionTime || 0;
        const slaCompliant = responseTime <= service.slaThresholdMs;
        
        if (!slaCompliant) {
          console.log(`  ‚ö†Ô∏è  SLA Warning: ${responseTime}ms (threshold: ${service.slaThresholdMs}ms)`);
        } else {
          console.log(`  ‚úÖ Healthy - ${responseTime}ms`);
        }
      },
      
      // Error handling
      finalErrorAnalyzer: async ({ error }) => {
        console.log(`  ‚ùå Health check failed: ${error}`);
        
        const currentFailures = failureTracker.get(service.name) || 0;
        failureTracker.set(service.name, currentFailures + 1);
        
        if (service.critical && currentFailures >= 2) {
          console.log(`  üö® ALERT: Critical service has ${currentFailures + 1} consecutive failures!`);
        }
        
        return false; // Throw error
      }
    });
    
    // Success - reset failure counter
    failureTracker.set(service.name, 0);
    
    const responseTime = Date.now() - startTime;
    const slaCompliant = responseTime <= service.slaThresholdMs;
    
    return {
      service: service.name,
      status: slaCompliant ? 'healthy' : 'degraded',
      responseTime,
      timestamp: new Date().toISOString(),
      consecutiveFailures: 0,
      circuitBreakerState: 'CLOSED',
      slaCompliant
    };
    
  } catch (error) {
    const consecutiveFailures = failureTracker.get(service.name) || 0;
    
    return {
      service: service.name,
      status: 'down',
      responseTime: Date.now() - startTime,
      timestamp: new Date().toISOString(),
      consecutiveFailures,
      circuitBreakerState: 'OPEN',
      slaCompliant: false
    };
  }
}

// Monitor all services
async function monitorServices() {
  console.log('üè• Starting Health Monitoring\n');
  
  const results = await Promise.all(
    services.map(service => checkServiceHealth(service))
  );
  
  console.log('\nüìä Health Monitoring Summary:');
  results.forEach(health => {
    const icon = health.status === 'healthy' ? '‚úÖ' : 
                 health.status === 'degraded' ? '‚ö†Ô∏è' : '‚ùå';
    console.log(`${icon} ${health.service}: ${health.status} (${health.responseTime}ms)`);
  });
}

// Run health checks periodically
setInterval(() => monitorServices(), 10000);
monitorServices(); // Run immediately</code></pre>
                </div>
            </div>

            <div class="example-item">
                <div class="example-header">
                    <span class="example-number">04</span>
                    <h2>Batch Image Processing Pipeline</h2>
                    <div class="example-tags">
                        <span class="tag">Batch Processing</span>
                        <span class="tag">Concurrency Control</span>
                        <span class="tag">Rate Limiting</span>
                        <span class="tag">Progress Tracking</span>
                    </div>
                </div>
                
                <div class="example-description">
                    <p>Process large batches of images through an external API with concurrency control, rate limiting, and progress tracking.</p>
                    
                    <h4>Key Features:</h4>
                    <ul>
                        <li>‚úÖ Batch request processing with stableApiGateway</li>
                        <li>‚úÖ Concurrency limiting (max 10 simultaneous)</li>
                        <li>‚úÖ Rate limiting to respect API quotas</li>
                        <li>‚úÖ Progress tracking and reporting</li>
                        <li>‚úÖ Retry on transient failures</li>
                        <li>‚úÖ Error aggregation and reporting</li>
                    </ul>
                </div>
                
                <div class="example-code">
                    <div class="example-actions">
                        <button class="btn btn-primary run-example-btn" data-example="04">
                            ‚ñ∂ Run Example
                        </button>
                        <button class="btn btn-secondary clear-output-btn" data-example="04" style="display:none;">
                            Clear Output
                        </button>
                    </div>
                    <div class="example-output" id="output-04" style="display:none;"></div>
                    <h4>Complete Working Example</h4>
                    <pre><code class="language-typescript">import { 
  stableApiGateway, 
  RETRY_STRATEGIES,
  RateLimiter,
  ConcurrencyLimiter,
  REQUEST_METHODS,
  VALID_REQUEST_PROTOCOLS,
  type API_GATEWAY_REQUEST
} from '@emmvish/stable-request';

// Image processing job types
interface ImageJob {
  id: string;
  imageUrl: string;
  operations: string[];
  priority: 'high' | 'normal' | 'low';
  size: 'small' | 'medium' | 'large';
}

// Simulated image processing jobs
const imageBatch: ImageJob[] = [
  { id: 'img-001', imageUrl: '/photos/1', operations: ['resize', 'thumbnail'], priority: 'high', size: 'large' },
  { id: 'img-002', imageUrl: '/photos/2', operations: ['watermark'], priority: 'normal', size: 'medium' },
  { id: 'img-003', imageUrl: '/photos/3', operations: ['compress'], priority: 'low', size: 'small' },
  { id: 'img-004', imageUrl: '/photos/4', operations: ['resize', 'compress'], priority: 'high', size: 'large' },
  { id: 'img-005', imageUrl: '/photos/5', operations: ['thumbnail'], priority: 'normal', size: 'small' },
  { id: 'img-006', imageUrl: '/photos/6', operations: ['watermark', 'compress'], priority: 'low', size: 'medium' },
  { id: 'img-007', imageUrl: '/photos/7', operations: ['resize'], priority: 'high', size: 'large' },
  { id: 'img-008', imageUrl: '/photos/8', operations: ['thumbnail', 'watermark'], priority: 'normal', size: 'medium' },
  { id: 'img-009', imageUrl: '/photos/9', operations: ['compress'], priority: 'low', size: 'small' },
  { id: 'img-010', imageUrl: '/photos/10', operations: ['resize', 'watermark'], priority: 'high', size: 'large' }
];

// Initialize rate limiter (20 requests per second)
const rateLimiter = new RateLimiter(1000, 20);

// Initialize concurrency limiter (max 5 concurrent requests)
const concurrencyLimiter = new ConcurrencyLimiter(5);

// Track processing results
const processingResults = {
  successful: [] as string[],
  failed: [] as string[],
  processingTimes: [] as number[]
};

// Process batch of images
async function processBatchImages() {
  const startTime = Date.now();
  
  console.log('üñºÔ∏è  Starting Batch Image Processing');
  console.log('‚ïê'.repeat(70));
  console.log(`Total Images: ${imageBatch.length}`);
  console.log(`Rate Limit: 20 req/sec | Concurrency Limit: 5 concurrent`);
  console.log('');
  
  // Convert jobs to API requests
  const requests: API_GATEWAY_REQUEST[] = imageBatch.map(job => ({
    id: job.id,
    groupId: job.priority,
    requestOptions: {
      reqData: {
        path: job.imageUrl,
        method: REQUEST_METHODS.GET
      },
      resReq: true,
      
      // Retry configuration based on priority
      attempts: job.priority === 'high' ? 5 : job.priority === 'normal' ? 3 : 2,
      wait: job.priority === 'high' ? 2000 : 1000,
      retryStrategy: RETRY_STRATEGIES.EXPONENTIAL,
      maxAllowedWait: 10000,
      
      // Apply rate and concurrency limiting
      rateLimiter: rateLimiter,
      concurrencyLimiter: concurrencyLimiter,
      
      // Success tracking
      handleSuccessfulAttemptData: async ({ successfulAttemptData }) => {
        processingResults.successful.push(job.id);
        processingResults.processingTimes.push(successfulAttemptData.executionTime || 0);
        
        const priorityIcon = job.priority === 'high' ? 'üî¥' : 
                           job.priority === 'normal' ? 'üü°' : 'üü¢';
        console.log(`  ${priorityIcon} ${job.id}: Processed ${job.operations.join(', ')} (${successfulAttemptData.executionTime}ms)`);
      },
      
      // Error handling
      finalErrorAnalyzer: async ({ error }) => {
        processingResults.failed.push(job.id);
        console.log(`  ‚ùå ${job.id}: Processing failed - ${error}`);
        return true; // Suppress error to continue with other images
      }
    }
  }));
  
  console.log('üîÑ Processing images...\n');
  
  // Execute batch processing with stableApiGateway
  const results = await stableApiGateway(requests, {
    concurrentExecution: true,
    
    // Common configuration
    commonRequestData: {
      hostname: 'jsonplaceholder.typicode.com',
      protocol: VALID_REQUEST_PROTOCOLS.HTTPS,
      headers: {
        'Content-Type': 'application/json',
        'X-Batch-ID': `BATCH-${Date.now()}`,
        'User-Agent': 'ImageProcessor/2.0'
      },
      timeout: 10000
    },
    
    // Request groups with different retry strategies
    requestGroups: [
      {
        id: 'high',
        commonConfig: {
          commonAttempts: 5,
          commonWait: 2000,
          commonRetryStrategy: RETRY_STRATEGIES.EXPONENTIAL
        }
      },
      {
        id: 'normal',
        commonConfig: {
          commonAttempts: 3,
          commonWait: 1000,
          commonRetryStrategy: RETRY_STRATEGIES.LINEAR
        }
      },
      {
        id: 'low',
        commonConfig: {
          commonAttempts: 2,
          commonWait: 500,
          commonRetryStrategy: RETRY_STRATEGIES.FIXED
        }
      }
    ],
    
    stopOnFirstError: false,
    commonAttempts: 3,
    commonWait: 1000
  });
  
  const duration = Date.now() - startTime;
  
  // Generate processing report
  console.log('\n' + '‚ïê'.repeat(70));
  console.log('üìä BATCH PROCESSING SUMMARY');
  console.log('‚ïê'.repeat(70));
  
  const successfulResults = results.filter(r => r.success);
  const failedResults = results.filter(r => !r.success);
  
  console.log(`\nProcessing Results:`);
  console.log(`  ‚úÖ Successful: ${successfulResults.length}/${imageBatch.length}`);
  console.log(`  ‚ùå Failed: ${failedResults.length}/${imageBatch.length}`);
  console.log(`  ‚è±Ô∏è  Total Duration: ${duration}ms`);
  
  if (processingResults.processingTimes.length > 0) {
    const avgTime = processingResults.processingTimes.reduce((a, b) => a + b, 0) / 
                    processingResults.processingTimes.length;
    console.log(`  üìà Average Time per Image: ${avgTime.toFixed(0)}ms`);
  }
  
  console.log('\n‚ú® Batch processing complete!');
  
  return {
    totalJobs: imageBatch.length,
    successful: successfulResults.length,
    failed: failedResults.length,
    duration,
    averageTime: processingResults.processingTimes.reduce((a, b) => a + b, 0) / 
                 processingResults.processingTimes.length
  };
}

// Run the batch processing
processBatchImages();</code></pre>
                </div>
            </div>

            <div class="example-item">
                <div class="example-header">
                    <span class="example-number">05</span>
                    <h2>Feature Flag Testing with Trial Mode</h2>
                    <div class="example-tags">
                        <span class="tag">A/B Testing</span>
                        <span class="tag">Trial Mode</span>
                        <span class="tag">Feature Flags</span>
                        <span class="tag">Testing</span>
                    </div>
                </div>
                
                <div class="example-description">
                    <p>Test feature flags and new implementations without making real API calls using trial mode with configurable success rates.</p>
                    
                    <h4>Key Features:</h4>
                    <ul>
                        <li>‚úÖ Trial mode for testing without real requests</li>
                        <li>‚úÖ Configurable success/failure probabilities</li>
                        <li>‚úÖ A/B testing simulation</li>
                        <li>‚úÖ Mock data injection</li>
                        <li>‚úÖ Performance testing under various conditions</li>
                    </ul>
                </div>
                
                <div class="example-code">
                    <div class="example-actions">
                        <button class="btn btn-primary run-example-btn" data-example="05">
                            ‚ñ∂ Run Example
                        </button>
                        <button class="btn btn-secondary clear-output-btn" data-example="05" style="display:none;">
                            Clear Output
                        </button>
                    </div>
                    <div class="example-output" id="output-05" style="display:none;"></div>
                    <h4>Complete Working Example</h4>
                    <pre><code class="language-typescript">import { 
  stableRequest, 
  RETRY_STRATEGIES,
  REQUEST_METHODS,
  VALID_REQUEST_PROTOCOLS
} from '@emmvish/stable-request';

// Test scenarios
interface ChaosScenario {
  name: string;
  description: string;
  failureProbability: number;
  retryFailureProbability?: number;
  expectedBehavior: string;
}

// Define chaos engineering scenarios
const chaosScenarios: ChaosScenario[] = [
  {
    name: 'Healthy System',
    description: 'No failures - baseline test',
    failureProbability: 0,
    expectedBehavior: 'All requests succeed immediately'
  },
  {
    name: 'Intermittent Failures',
    description: '30% initial failure rate with recovery',
    failureProbability: 0.3,
    retryFailureProbability: 0.1,
    expectedBehavior: 'Some requests fail initially but recover on retry'
  },
  {
    name: 'High Failure Rate',
    description: '70% failure rate with some recovery',
    failureProbability: 0.7,
    retryFailureProbability: 0.4,
    expectedBehavior: 'Most requests require multiple retries'
  },
  {
    name: 'Persistent Failures',
    description: '50% failure rate that persists',
    failureProbability: 0.5,
    retryFailureProbability: 0.9,
    expectedBehavior: 'Significant failures even after retries'
  },
  {
    name: 'Complete Outage',
    description: '100% failure rate - total unavailability',
    failureProbability: 1.0,
    retryFailureProbability: 1.0,
    expectedBehavior: 'All requests fail after exhausting retries'
  }
];

// Track test results
interface TestResult {
  scenario: string;
  success: boolean;
  attempts: number;
  duration: number;
  error?: string;
}

const testResults: TestResult[] = [];

// Run chaos test for a single scenario
async function runChaosTest(scenario: ChaosScenario): Promise<TestResult> {
  console.log(`\nüß™ Testing: ${scenario.name}`);
  console.log(`   ${scenario.description}`);
  console.log(`   Failure Rate: ${(scenario.failureProbability * 100).toFixed(0)}% initial`);
  
  const startTime = Date.now();
  let attemptCount = 0;
  
  try {
    await stableRequest({
      reqData: {
        hostname: 'api.example.com',
        protocol: VALID_REQUEST_PROTOCOLS.HTTPS,
        path: '/chaos-test',
        method: REQUEST_METHODS.GET,
        headers: {
          'X-Test-Scenario': scenario.name
        },
        timeout: 5000
      },
      
      // Configure retry behavior
      attempts: 5,
      wait: 500,
      retryStrategy: RETRY_STRATEGIES.EXPONENTIAL,
      maxAllowedWait: 3000,
      
      // Enable trial mode for failure simulation
      trialMode: {
        enabled: true,
        reqFailureProbability: scenario.failureProbability,
        retryFailureProbability: scenario.retryFailureProbability
      },
      
      // Track all attempts
      handleSuccessfulAttemptData: async ({ successfulAttemptData }) => {
        attemptCount = parseInt(successfulAttemptData.attempt?.split('/')[0] || '1');
        if (attemptCount > 1) {
          console.log(`   ‚úÖ Recovered on attempt ${attemptCount} (${successfulAttemptData.executionTime}ms)`);
        } else {
          console.log(`   ‚úÖ Succeeded immediately (${successfulAttemptData.executionTime}ms)`);
        }
      },
      
      // Error analysis
      finalErrorAnalyzer: async ({ error }) => {
        console.log(`   ‚ùå Failed: ${error}`);
        return false; // Re-throw
      },
      
      resReq: true
    });
    
    const duration = Date.now() - startTime;
    
    return {
      scenario: scenario.name,
      success: true,
      attempts: attemptCount,
      duration
    };
    
  } catch (error) {
    const duration = Date.now() - startTime;
    
    return {
      scenario: scenario.name,
      success: false,
      attempts: attemptCount,
      duration,
      error: error instanceof Error ? error.message : String(error)
    };
  }
}

// Run all chaos engineering tests
async function runChaosEngineeringTests() {
  console.log('üå™Ô∏è  Starting Chaos Engineering Tests');
  console.log('‚ïê'.repeat(70));
  console.log('Testing system resilience under various failure scenarios');
  console.log(`Total Scenarios: ${chaosScenarios.length}`);
  console.log('‚ïê'.repeat(70));
  
  // Run each scenario
  for (const scenario of chaosScenarios) {
    const result = await runChaosTest(scenario);
    testResults.push(result);
    await new Promise(resolve => setTimeout(resolve, 200));
  }
  
  // Generate comprehensive resilience report
  console.log('\n' + '‚ïê'.repeat(70));
  console.log('üìä CHAOS ENGINEERING RESULTS');
  console.log('‚ïê'.repeat(70));
  
  const successfulTests = testResults.filter(r => r.success).length;
  console.log(`\nOverall Statistics:`);
  console.log(`  Tests Passed: ${successfulTests}/${testResults.length}`);
  console.log(`  Tests Failed: ${testResults.length - successfulTests}/${testResults.length}`);
  
  console.log(`\nResilience Analysis:`);
  testResults.forEach((result, index) => {
    const scenario = chaosScenarios[index];
    const icon = result.success ? '‚úÖ' : '‚ùå';
    
    console.log(`\n${icon} ${result.scenario}:`);
    console.log(`   Expected: ${scenario.expectedBehavior}`);
    console.log(`   Result: ${result.success ? 'SUCCESS' : 'FAILED'}`);
    console.log(`   Attempts Used: ${result.attempts}`);
    console.log(`   Duration: ${result.duration}ms`);
    
    if (result.error) {
      console.log(`   Error: ${result.error}`);
    }
  });
  
  console.log('\n' + '‚ïê'.repeat(70));
  console.log('‚úÖ Chaos engineering tests complete!');
  
  return {
    totalTests: testResults.length,
    passed: successfulTests,
    failed: testResults.length - successfulTests,
    results: testResults
  };
}

// Run chaos engineering tests
runChaosEngineeringTests();</code></pre>
                </div>
            </div>

            <div class="example-item">
                <div class="example-header">
                    <span class="example-number">06</span>
                    <h2>Distributed Workflow State Persistence</h2>
                    <div class="example-tags">
                        <span class="tag">State Persistence</span>
                        <span class="tag">Workflow Recovery</span>
                        <span class="tag">Distributed Systems</span>
                        <span class="tag">Redis</span>
                        <span class="tag">Checkpointing</span>
                    </div>
                </div>
                
                <div class="example-description">
                    <p>A production-grade distributed data processing workflow with Redis-based state persistence, enabling workflow recovery, resumption, and distributed execution across multiple instances.</p>
                    
                    <h4>Key Features:</h4>
                    <ul>
                        <li>‚úÖ State persistence to Redis with TTL</li>
                        <li>‚úÖ Workflow recovery and resumption after failures</li>
                        <li>‚úÖ Multi-stage data pipeline with checkpoints</li>
                        <li>‚úÖ Distributed lock mechanisms for safety</li>
                        <li>‚úÖ State versioning and audit trails</li>
                        <li>‚úÖ Real-time progress tracking across instances</li>
                        <li>‚úÖ Automatic cleanup of completed workflows</li>
                        <li>‚úÖ Phase completion tracking and skip logic</li>
                        <li>‚úÖ Hierarchical state keys for organization</li>
                        <li>‚úÖ Batch processing with concurrent migrations</li>
                    </ul>
                    
                    <h4>Use Case:</h4>
                    <p>Large-scale data migration pipeline that can be resumed from any checkpoint, run across multiple server instances, and provide real-time progress visibility. Perfect for long-running workflows that need resilience against failures.</p>
                </div>
                
                <div class="example-code">
                    <div class="example-actions">
                        <button class="btn btn-primary run-example-btn" data-example="06">
                            ‚ñ∂ Run Example
                        </button>
                        <button class="btn btn-secondary clear-output-btn" data-example="06" style="display:none;">
                            Clear Output
                        </button>
                    </div>
                    <div class="example-output" id="output-06" style="display:none;"></div>
                    <h4>Complete Working Example</h4>
                    <pre><code class="language-typescript">import { 
  stableWorkflow, 
  PHASE_DECISION_ACTIONS,
  REQUEST_METHODS,
  VALID_REQUEST_PROTOCOLS,
  type STABLE_WORKFLOW_PHASE,
  type StatePersistenceOptions
} from '@emmvish/stable-request';

// ============================================================================
// STATE PERSISTENCE LAYER
// ============================================================================

/**
 * Simulated Redis-like storage
 * In production, use actual Redis client (ioredis or node-redis)
 */
class StateStorage {
  private storage: Map<string, { value: string; expiresAt: number }> = new Map();

  async setex(key: string, ttl: number, value: string): Promise<void> {
    const expiresAt = Date.now() + (ttl * 1000);
    this.storage.set(key, { value, expiresAt });
    console.log(`    üíæ Stored state: ${key}`);
  }

  async get(key: string): Promise<string | null> {
    const entry = this.storage.get(key);
    if (!entry || Date.now() > entry.expiresAt) return null;
    console.log(`    üì• Loaded state: ${key}`);
    return entry.value;
  }

  async del(key: string): Promise<void> {
    this.storage.delete(key);
  }
}

const stateStore = new StateStorage();

/**
 * Redis persistence function with distributed locking
 */
async function persistToRedis({ executionContext, params, buffer }: StatePersistenceOptions): Promise<Record<string, any>> {
  const { workflowId, phaseId, branchId } = executionContext;
  const { ttl = 86400, enableLocking = false, namespace = 'workflow' } = params || {};
  
  // Generate hierarchical state key
  const stateKey = `${namespace}:${workflowId}:${branchId || 'main'}:${phaseId || 'global'}`;
  const lockKey = `lock:${stateKey}`;
  
  const isStoring = buffer && Object.keys(buffer).length > 0;
  
  if (enableLocking) {
    await stateStore.setex(lockKey, 5, `${Date.now()}-${Math.random()}`);
  }
  
  try {
    if (isStoring) {
      // STORE MODE
      const stateWithMeta = {
        ...buffer,
        _meta: {
          workflowId,
          phaseId,
          timestamp: new Date().toISOString(),
          version: (buffer._meta?.version || 0) + 1
        }
      };
      
      await stateStore.setex(stateKey, ttl, JSON.stringify(stateWithMeta));
      
      // Audit log
      const auditKey = `${namespace}:audit:${workflowId}:${Date.now()}`;
      await stateStore.setex(auditKey, ttl * 2, JSON.stringify({
        action: 'state_saved',
        phaseId,
        timestamp: new Date().toISOString()
      }));
    } else {
      // LOAD MODE
      const data = await stateStore.get(stateKey);
      return data ? JSON.parse(data) : {};
    }
  } finally {
    if (enableLocking) {
      await stateStore.del(lockKey);
    }
  }
  
  return {};
}

/**
 * Checkpoint persistence for phase completion tracking
 */
async function createCheckpoint({ executionContext, params, buffer }: StatePersistenceOptions): Promise<Record<string, any>> {
  const { workflowId, phaseId } = executionContext;
  const { ttl = 86400 } = params || {};
  
  const checkpointKey = `checkpoint:${workflowId || 'default'}`;
  
  if (buffer && Object.keys(buffer).length > 0) {
    const existingData = await stateStore.get(checkpointKey);
    const existing = existingData ? JSON.parse(existingData) : {};
    
    const checkpointData = {
      ...existing,
      completedPhases: [...new Set([...(existing.completedPhases || []), ...(buffer.completedPhases || [])])],
      lastPhase: phaseId || existing.lastPhase,
      lastUpdated: new Date().toISOString(),
      progress: buffer.progress || existing.progress || 0,
      processedRecords: buffer.recordsProcessed || existing.processedRecords || 0
    };
    
    await stateStore.setex(checkpointKey, ttl, JSON.stringify(checkpointData));
    console.log(`    ‚úÖ Checkpoint saved (Progress: ${checkpointData.progress}%)`);
  } else {
    const data = await stateStore.get(checkpointKey);
    return data ? JSON.parse(data) : { completedPhases: [], processedRecords: 0 };
  }
  
  return {};
}

// ============================================================================
// WORKFLOW STATE
// ============================================================================

interface WorkflowState {
  sourceRecords: any[];
  transformedRecords: any[];
  validatedRecords: any[];
  migratedRecords: any[];
  failedRecords: any[];
  completedPhases: string[];
  currentPhase: string;
  progress: number;
  recordsProcessed: number;
  totalRecords: number;
  startTime: number;
  lastUpdateTime: number;
  attemptCount: number;
  errors: string[];
  canResume: boolean;
  resumeFromPhase: string | null;
}

const workflowState: WorkflowState = {
  sourceRecords: [],
  transformedRecords: [],
  validatedRecords: [],
  migratedRecords: [],
  failedRecords: [],
  completedPhases: [],
  currentPhase: '',
  progress: 0,
  recordsProcessed: 0,
  totalRecords: 0,
  startTime: Date.now(),
  lastUpdateTime: Date.now(),
  attemptCount: 0,
  errors: [],
  canResume: true,
  resumeFromPhase: null
};

// ============================================================================
// WORKFLOW DEFINITION
// ============================================================================

const WORKFLOW_ID = `migration-${Date.now()}`;
const SOURCE_API = 'jsonplaceholder.typicode.com';

const migrationPhases: STABLE_WORKFLOW_PHASE[] = [
  // PHASE 1: Data Extraction
  {
    id: 'extract-source-data',
    requests: [
      {
        id: 'extract-users',
        requestOptions: {
          reqData: { 
            hostname: SOURCE_API,
            path: '/posts/1',
            method: REQUEST_METHODS.GET
          },
          resReq: false,
          preExecution: {
            preExecutionHook: ({ commonBuffer }) => {
              console.log('\nüì• Phase 1: Extracting source data...');
              const buffer = commonBuffer as WorkflowState;
              
              // Generate mock data
              buffer.sourceRecords = Array.from({ length: 100 }, (_, i) => ({
                id: i + 1,
                name: `User ${i + 1}`,
                email: `user${i + 1}@example.com`,
                username: `user${i + 1}`,
                company: { name: `Company ${i % 10}` },
                address: { geo: { lat: '0.0', lng: '0.0' } }
              }));
              
              buffer.totalRecords = buffer.sourceRecords.length;
              buffer.progress = 20;
              buffer.recordsProcessed = buffer.sourceRecords.length;
              console.log(`  ‚úÖ Extracted ${buffer.sourceRecords.length} records`);
              return {};
            },
            applyPreExecutionConfigOverride: false
          }
        }
      }
    ],
    phaseDecisionHook: async ({ phaseResult, sharedBuffer }) => {
      const buffer = sharedBuffer as WorkflowState;
      
      if (buffer.completedPhases.includes('extract-source-data')) {
        console.log(`  ‚è© Phase already completed, skipping...`);
        return { action: PHASE_DECISION_ACTIONS.SKIP, skipToPhaseId: 'transform-data' };
      }
      
      if (phaseResult.success && buffer.sourceRecords.length > 0) {
        buffer.completedPhases.push('extract-source-data');
        return { action: PHASE_DECISION_ACTIONS.CONTINUE };
      }
      
      return { action: PHASE_DECISION_ACTIONS.TERMINATE };
    },
    statePersistence: {
      persistenceFunction: persistToRedis,
      persistenceParams: { ttl: 3600, enableLocking: true, namespace: 'migration' },
      loadBeforeHooks: true,
      storeAfterHooks: true
    }
  },

  // PHASE 2: Data Transformation
  {
    id: 'transform-data',
    requests: [
      {
        id: 'transform-records',
        requestOptions: {
          reqData: { 
            hostname: SOURCE_API,
            path: '/posts/1',
            method: REQUEST_METHODS.GET
          },
          resReq: false,
          preExecution: {
            preExecutionHook: ({ commonBuffer }) => {
              console.log('\nüîÑ Phase 2: Transforming data...');
              const buffer = commonBuffer as WorkflowState;
              
              buffer.transformedRecords = buffer.sourceRecords.map(record => ({
                id: record.id,
                externalId: record.id,
                name: record.name,
                email: record.email?.toLowerCase(),
                username: record.username,
                company: record.company?.name,
                metadata: {
                  importedAt: new Date().toISOString(),
                  source: 'jsonplaceholder',
                  workflowId: WORKFLOW_ID
                }
              }));
              
              buffer.progress = 40;
              console.log(`  ‚úÖ Transformed ${buffer.transformedRecords.length} records`);
              return {};
            },
            applyPreExecutionConfigOverride: false
          }
        }
      }
    ],
    phaseDecisionHook: async ({ phaseResult, sharedBuffer }) => {
      const buffer = sharedBuffer as WorkflowState;
      
      if (buffer.completedPhases.includes('transform-data')) {
        console.log(`  ‚è© Phase already completed, skipping...`);
        return { action: PHASE_DECISION_ACTIONS.SKIP, skipToPhaseId: 'validate-data' };
      }
      
      if (phaseResult.success && buffer.transformedRecords.length > 0) {
        buffer.completedPhases.push('transform-data');
        return { action: PHASE_DECISION_ACTIONS.CONTINUE };
      }
      
      if (buffer.attemptCount < 2) {
        buffer.attemptCount++;
        return { action: PHASE_DECISION_ACTIONS.REPLAY };
      }
      
      return { action: PHASE_DECISION_ACTIONS.TERMINATE };
    },
    allowReplay: true,
    maxReplayCount: 2,
    statePersistence: {
      persistenceFunction: persistToRedis,
      persistenceParams: { ttl: 3600, enableLocking: true, namespace: 'migration' },
      loadBeforeHooks: true,
      storeAfterHooks: true
    }
  },

  // PHASE 3: Data Validation
  {
    id: 'validate-data',
    requests: [
      {
        id: 'validate-records',
        requestOptions: {
          reqData: { 
            hostname: SOURCE_API,
            path: '/posts/1',
            method: REQUEST_METHODS.GET
          },
          resReq: false,
          preExecution: {
            preExecutionHook: ({ commonBuffer }) => {
              console.log('\nüîç Phase 3: Validating data...');
              const buffer = commonBuffer as WorkflowState;
              
              buffer.validatedRecords = buffer.transformedRecords.filter(record => {
                return record.email && record.email.includes('@') && 
                       record.name && record.name.length >= 3;
              });
              
              buffer.failedRecords = buffer.transformedRecords.filter(record => {
                return !record.email || !record.email.includes('@') || 
                       !record.name || record.name.length < 3;
              });
              
              buffer.progress = 70;
              console.log(`  ‚úÖ Validated: ${buffer.validatedRecords.length} passed, ${buffer.failedRecords.length} failed`);
              return {};
            },
            applyPreExecutionConfigOverride: false
          }
        }
      }
    ],
    phaseDecisionHook: async ({ phaseResult, sharedBuffer }) => {
      const buffer = sharedBuffer as WorkflowState;
      
      if (buffer.completedPhases.includes('validate-data')) {
        console.log(`  ‚è© Phase already completed, skipping...`);
        return { action: PHASE_DECISION_ACTIONS.SKIP, skipToPhaseId: 'migrate-data' };
      }
      
      if (phaseResult.success && buffer.validatedRecords.length > 0) {
        buffer.completedPhases.push('validate-data');
        return { action: PHASE_DECISION_ACTIONS.CONTINUE };
      }
      
      return { action: PHASE_DECISION_ACTIONS.TERMINATE };
    },
    statePersistence: {
      persistenceFunction: persistToRedis,
      persistenceParams: { ttl: 3600, enableLocking: true, namespace: 'migration' },
      loadBeforeHooks: true,
      storeAfterHooks: true
    }
  }
];

// ============================================================================
// WORKFLOW EXECUTION
// ============================================================================

console.log('üöÄ Starting Distributed Workflow with State Persistence');
console.log(`Workflow ID: ${WORKFLOW_ID}\n`);

const result = await stableWorkflow(migrationPhases, {
  workflowId: WORKFLOW_ID,
  commonRequestData: { 
    hostname: SOURCE_API,
    protocol: VALID_REQUEST_PROTOCOLS.HTTPS
  },
  enableNonLinearExecution: true,
  stopOnFirstPhaseError: false,
  maxWorkflowIterations: 100,
  sharedBuffer: workflowState,
  commonStatePersistence: {
    persistenceFunction: createCheckpoint,
    persistenceParams: { ttl: 7200 },
    loadBeforeHooks: true,
    storeAfterHooks: true
  },
  handlePhaseCompletion: async ({ phaseResult, sharedBuffer }) => {
    const buffer = sharedBuffer as WorkflowState;
    console.log(`\n‚úÖ Phase "${phaseResult.phaseId}" completed`);
    console.log(`   Duration: ${phaseResult.executionTime}ms`);
    console.log(`   Progress: ${buffer.progress}%`);
  }
});

console.log('\nüìä Workflow Results:');
console.log(`Success: ${result.success}`);
console.log(`Total Phases: ${result.totalPhases}`);
console.log(`Duration: ${result.executionTime}ms`);
console.log(`Records Processed: ${workflowState.recordsProcessed}`);</code></pre>
                    
                    <h4>Workflow Recovery Pattern</h4>
                    <pre><code class="language-typescript">/**
 * Resume workflow from last checkpoint
 * This function demonstrates how to recover and resume a failed workflow
 */
async function resumeWorkflow(workflowId: string) {
  // Load checkpoint from storage
  const checkpointData = await stateStore.get(`checkpoint:${workflowId}`);
  const checkpoint = checkpointData ? JSON.parse(checkpointData) : {
    completedPhases: [],
    processedRecords: 0
  };
  
  console.log(`üìÇ Resuming workflow: ${workflowId}`);
  console.log(`   Last phase: ${checkpoint.lastPhase || 'start'}`);
  console.log(`   Completed: ${checkpoint.completedPhases.join(', ') || 'none'}`);
  
  // Restore state from checkpoint
  const restoredState: WorkflowState = {
    ...workflowState,
    completedPhases: checkpoint.completedPhases,
    processedRecords: checkpoint.processedRecords,
    progress: checkpoint.progress || 0
  };
  
  // Execute workflow - completed phases will be skipped automatically
  const result = await stableWorkflow(migrationPhases, {
    workflowId,
    commonRequestData: { 
      hostname: SOURCE_API,
      protocol: VALID_REQUEST_PROTOCOLS.HTTPS
    },
    enableNonLinearExecution: true,
    sharedBuffer: restoredState,
    commonStatePersistence: {
      persistenceFunction: createCheckpoint,
      persistenceParams: { ttl: 7200 },
      loadBeforeHooks: true,
      storeAfterHooks: true
    }
  });
  
  console.log(`\n‚úÖ Workflow resumed and ${result.success ? 'completed' : 'failed'}`);
  return result;
}

// Example usage: Can be called multiple times to resume from last checkpoint
// await resumeWorkflow('migration-12345');</code></pre>
                </div>
            </div>

            <div class="example-item">
                <div class="example-header">
                    <span class="example-number">07</span>
                    <h2>Real-Time Metrics Monitoring & Performance Dashboard</h2>
                    <div class="example-tags">
                        <span class="tag">Metrics</span>
                        <span class="tag">Performance Monitoring</span>
                        <span class="tag">Alerting</span>
                        <span class="tag">Health Score</span>
                        <span class="tag">SLA Tracking</span>
                    </div>
                </div>
                
                <div class="example-description">
                    <p>A comprehensive real-time metrics monitoring system demonstrating all 9 MetricsAggregator methods, automated SLA tracking, performance alerting, and health score calculation across workflow, phase, branch, and infrastructure levels.</p>
                    
                    <h4>Key Features:</h4>
                    <ul>
                        <li><strong>‚úÖ Multi-Level Metrics:</strong> Workflow, phase, branch, and request group metrics</li>
                        <li><strong>‚úÖ Infrastructure Monitoring:</strong> Circuit breaker, cache, rate limiter, and concurrency limiter metrics</li>
                        <li><strong>‚úÖ Automated Alerting:</strong> SLA threshold monitoring with critical, warning, and info alerts</li>
                        <li><strong>‚úÖ Health Scoring:</strong> Automated system health score calculation (0-100 scale)</li>
                        <li><strong>‚úÖ Performance Dashboard:</strong> Real-time visualization of all metrics and KPIs</li>
                        <li><strong>‚úÖ Bottleneck Detection:</strong> Identifies performance issues and provides recommendations</li>
                        <li><strong>‚úÖ Comprehensive Analysis:</strong> Success rates, throughput, execution times, and resource utilization</li>
                    </ul>

                    <h4>Use Case:</h4>
                    <p>Enterprise-grade monitoring system tracking API performance, infrastructure health, and SLA compliance with automated alerting and health scoring for production environments.</p>
                </div>
                
                <div class="example-code">
                    <div class="example-actions">
                        <button class="btn btn-primary run-example-btn" data-example="07">
                            ‚ñ∂ Run Example
                        </button>
                        <button class="btn btn-secondary clear-output-btn" data-example="07" style="display:none;">
                            Clear Output
                        </button>
                    </div>
                    <div class="example-output" id="output-07" style="display:none;"></div>
                    <h4>Complete Working Example</h4>
                    <pre><code class="language-typescript">import {
  stableWorkflow,
  MetricsAggregator,
  CircuitBreaker,
  CacheManager,
  RateLimiter,
  ConcurrencyLimiter,
  RETRY_STRATEGIES,
  REQUEST_METHODS
} from '@emmvish/stable-request';

// SLA Thresholds for alerting
const SLA_THRESHOLDS = {
  maxPhaseExecutionTime: 5000,      // 5 seconds per phase
  maxWorkflowExecutionTime: 15000,  // 15 seconds total
  minSuccessRate: 95,                // 95% success rate
  maxAverageRequestTime: 1000,      // 1 second average
  maxThroughput: 50                  // 50 requests/second target
};

const ALERT_LEVELS = {
  CRITICAL: 'CRITICAL',
  WARNING: 'WARNING',
  INFO: 'INFO'
} as const;

// Infrastructure setup
const circuitBreaker = new CircuitBreaker({
  failureThresholdPercentage: 50,
  minimumRequests: 5,
  recoveryTimeoutMs: 10000
});

const cache = new CacheManager({
  enabled: true,
  ttl: 30000,
  maxSize: 200
});

const rateLimiter = new RateLimiter(50, 10000);
const concurrencyLimiter = new ConcurrencyLimiter(10);

// Metrics Monitor with automated alerting
class MetricsMonitor {
  private alerts = [];

  analyzeWorkflowMetrics(metrics) {
    this.alerts = [];

    // Analyze workflow performance
    if (metrics.workflow) {
      if (metrics.workflow.executionTime > SLA_THRESHOLDS.maxWorkflowExecutionTime) {
        this.addAlert({
          level: 'CRITICAL',
          component: 'Workflow',
          message: 'Execution time exceeded SLA',
          value: metrics.workflow.executionTime,
          threshold: SLA_THRESHOLDS.maxWorkflowExecutionTime
        });
      }

      if (metrics.workflow.requestSuccessRate < SLA_THRESHOLDS.minSuccessRate) {
        this.addAlert({
          level: 'CRITICAL',
          component: 'Workflow',
          message: 'Success rate below threshold',
          value: metrics.workflow.requestSuccessRate,
          threshold: SLA_THRESHOLDS.minSuccessRate
        });
      }

      if (metrics.workflow.throughput < SLA_THRESHOLDS.maxThroughput) {
        this.addAlert({
          level: 'WARNING',
          component: 'Workflow',
          message: 'Throughput below target',
          value: metrics.workflow.throughput.toFixed(2),
          threshold: SLA_THRESHOLDS.maxThroughput
        });
      }
    }

    // Analyze infrastructure health
    if (metrics.circuitBreaker?.state === 'OPEN') {
      this.addAlert({
        level: 'CRITICAL',
        component: 'Circuit Breaker',
        message: 'Circuit breaker is OPEN',
        value: 'OPEN'
      });
    }

    if (metrics.cache?.hitRate < 30 && metrics.cache?.totalRequests > 10) {
      this.addAlert({
        level: 'INFO',
        component: 'Cache',
        message: 'Low cache hit rate',
        value: metrics.cache.hitRate,
        threshold: 30
      });
    }

    return this.alerts;
  }

  generateHealthScore() {
    const criticalCount = this.alerts.filter(a => a.level === 'CRITICAL').length;
    const warningCount = this.alerts.filter(a => a.level === 'WARNING').length;
    
    let score = 100;
    score -= criticalCount * 25;
    score -= warningCount * 10;
    
    return Math.max(0, Math.min(100, score));
  }

  private addAlert(alert) {
    this.alerts.push(alert);
  }
}

// Execute multi-branch workflow with comprehensive metrics
const result = await stableWorkflow([], {
  workflowId: 'metrics-monitoring-demo',
  enableBranchExecution: true,
  branches: [
    {
      id: 'data-collection',
      phases: [
        {
          id: 'fetch-users',
          requests: [
            { id: 'users-list', requestOptions: { reqData: { path: '/users' }, resReq: true } },
            { id: 'user-1', requestOptions: { reqData: { path: '/users/1' }, resReq: true } },
            { id: 'user-2', requestOptions: { reqData: { path: '/users/2' }, resReq: true } }
          ],
          concurrentExecution: true
        },
        {
          id: 'fetch-posts',
          requests: Array.from({ length: 15 }, (_, i) => ({
            id: `post-${i + 1}`,
            requestOptions: { reqData: { path: `/posts/${i + 1}` }, resReq: true }
          })),
          concurrentExecution: true
        }
      ]
    },
    {
      id: 'data-processing',
      markConcurrentBranch: true,
      phases: [
        {
          id: 'fetch-comments',
          requests: Array.from({ length: 10 }, (_, i) => ({
            id: `comment-${i + 1}`,
            requestOptions: { reqData: { path: `/comments?postId=${i + 1}` }, resReq: true }
          })),
          concurrentExecution: true
        }
      ]
    },
    {
      id: 'data-enrichment',
      markConcurrentBranch: true,
      phases: [
        {
          id: 'fetch-albums',
          requests: Array.from({ length: 8 }, (_, i) => ({
            id: `album-${i + 1}`,
            requestOptions: { reqData: { path: `/albums/${i + 1}` }, resReq: true }
          })),
          concurrentExecution: true
        },
        {
          id: 'fetch-photos',
          requests: Array.from({ length: 5 }, (_, i) => ({
            id: `photo-${i + 1}`,
            requestOptions: { reqData: { path: `/photos?albumId=${i + 1}` }, resReq: true }
          })),
          concurrentExecution: true
        }
      ]
    }
  ],
  commonRequestData: { hostname: 'jsonplaceholder.typicode.com' },
  commonAttempts: 2,
  commonRetryStrategy: RETRY_STRATEGIES.EXPONENTIAL,
  circuitBreaker,
  commonCache: { enabled: true, ttl: 30000 },
  rateLimit: { maxRequests: 50, windowMs: 10000 },
  maxConcurrentRequests: 10,
  handleBranchCompletion: ({ branchId, success }) => {
    console.log(`Branch ${branchId}: ${success ? 'SUCCESS' : 'FAILED'}`);
  }
});

// Extract all metrics using MetricsAggregator
const systemMetrics = MetricsAggregator.aggregateSystemMetrics(
  result,
  circuitBreaker,
  cache,
  rateLimiter,
  concurrencyLimiter
);

console.log('Workflow Metrics:', systemMetrics.workflow);
console.log('Branch Metrics:', systemMetrics.branches);
console.log('Infrastructure Metrics:', {
  circuitBreaker: systemMetrics.circuitBreaker,
  cache: systemMetrics.cache,
  rateLimiter: systemMetrics.rateLimiter,
  concurrencyLimiter: systemMetrics.concurrencyLimiter
});

// Analyze metrics and generate alerts
const monitor = new MetricsMonitor();
const alerts = monitor.analyzeWorkflowMetrics(systemMetrics);
const healthScore = monitor.generateHealthScore();

console.log(`\nHealth Score: ${healthScore}/100`);
console.log(`Alerts: ${alerts.length}`);</code></pre>
                </div>
            </div>
        </div>

        <section class="next-steps">
            <h2>Ready to Get Started?</h2>
            <p>Explore the documentation to learn how to implement these patterns in your own applications.</p>
            <div class="cta-buttons">
                <a href="documentation.html" class="btn btn-primary">View Documentation</a>
                <a href="https://github.com/Emmvish/stable-request/tree/main/examples" class="btn btn-secondary">View Full Examples on GitHub</a>
            </div>
        </section>
    </div>

    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h4>stable-request</h4>
                    <p>Production-grade HTTP Workflow Engine for Node.js</p>
                </div>
                <div class="footer-section">
                    <h4>Links</h4>
                    <ul>
                        <li><a href="https://github.com/Emmvish/stable-request/blob/main/docs/api-references.md">API Reference</a></li>
                        <li><a href="https://github.com/Emmvish/stable-request/issues">Report Issues</a></li>
                        <li><a href="https://github.com/Emmvish/stable-request">GitHub</a></li>
                        <li><a href="https://www.npmjs.com/package/@emmvish/stable-request">NPM</a></li>
                        <li><a href="index.html">Home</a></li>
                    </ul>
                </div>
                <div class="footer-section">
                    <h4>Resources</h4>
                    <ul>
                        <li><a href="documentation.html">Documentation</a></li>
                        <li><a href="examples.html">Examples</a></li>
                    </ul>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2026 Manish Varma (Emmvish).</p>
            </div>
        </div>
    </footer>

    <script>
        hljs.highlightAll();
        
        // Utility functions for logging
        function log(outputId, message, type = 'info') {
            const output = document.getElementById(`output-${outputId}`);
            const timestamp = new Date().toLocaleTimeString();
            const colors = {
                info: '#64b5f6',
                success: '#81c784',
                warning: '#ffb74d',
                error: '#e57373',
                phase: '#ba68c8'
            };
            const icons = {
                info: '‚ÑπÔ∏è',
                success: '‚úÖ',
                warning: '‚ö†Ô∏è',
                error: '‚ùå',
                phase: 'üìç'
            };
            const line = document.createElement('div');
            line.style.marginBottom = '8px';
            line.style.color = colors[type];
            line.innerHTML = `<span style="color: #78909c">[${timestamp}]</span> ${icons[type]} ${message}`;
            output.appendChild(line);
            output.parentElement.scrollTop = output.parentElement.scrollHeight;
        }

        function delay(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }

        // Simulate API call
        async function simulateRequest(endpoint, options = {}) {
            await delay(300 + Math.random() * 700);
            if (Math.random() > 0.1) { // 90% success rate
                return { success: true, data: options.mockData || { status: 'ok' } };
            }
            throw new Error('Request failed');
        }

        // Example 01: Data Synchronization Pipeline
        async function runExample01(outputId) {
            log(outputId, 'üöÄ Starting Multi-Source Data Synchronization Pipeline', 'info');
            log(outputId, 'Workflow ID: data-sync-pipeline', 'info');
            
            try {
                // Phase 1: Fetch data concurrently
                log(outputId, 'üìç Phase 1: Fetching data from multiple sources', 'phase');
                await delay(500);
                
                log(outputId, 'GET https://jsonplaceholder.typicode.com/users?_limit=5', 'info');
                await simulateRequest('/users?_limit=5');
                log(outputId, '‚úì Fetched 5 users successfully', 'success');
                await delay(200);
                
                log(outputId, 'GET https://jsonplaceholder.typicode.com/posts?_limit=10', 'info');
                await simulateRequest('/posts?_limit=10');
                log(outputId, '‚úì Fetched 10 posts successfully', 'success');
                await delay(200);
                
                log(outputId, 'GET https://jsonplaceholder.typicode.com/comments?_limit=20', 'info');
                await simulateRequest('/comments?_limit=20');
                log(outputId, '‚úì Fetched 20 comments successfully', 'success');
                await delay(200);
                
                log(outputId, 'Phase 1 completed in 1250ms', 'success');
                
                // Phase 2: Data enrichment
                log(outputId, 'üìç Phase 2: Enriching data', 'phase');
                await delay(500);
                log(outputId, 'Matching posts with authors...', 'info');
                await delay(400);
                log(outputId, 'Calculating comment statistics...', 'info');
                await delay(400);
                log(outputId, '‚úì Enriched 10 posts with author and comment data', 'success');
                log(outputId, 'Average comments per post: 2.0', 'info');
                log(outputId, 'Phase 2 completed in 890ms', 'success');
                
                // Phase 3: Validation
                log(outputId, 'üìç Phase 3: Validating enriched data', 'phase');
                await delay(400);
                log(outputId, 'Validating post titles (1-100 chars)...', 'info');
                await delay(300);
                log(outputId, 'Validating comment counts (>= 0)...', 'info');
                await delay(300);
                log(outputId, '‚úì All 10 records passed validation', 'success');
                log(outputId, 'Phase 3 completed in 650ms', 'success');
                
                // Phase 4: Batch upload
                log(outputId, 'üìç Phase 4: Uploading to internal system', 'phase');
                await delay(300);
                
                for (let i = 1; i <= 5; i++) {
                    log(outputId, `POST /api/sync/batch-${i}`, 'info');
                    await simulateRequest('/api/sync', { mockData: { batchId: i } });
                    log(outputId, `‚úì Batch ${i}/5 uploaded (2 records)`, 'success');
                    await delay(200);
                }
                log(outputId, 'Phase 4 completed in 1420ms', 'success');
                
                // Final summary
                await delay(300);
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üéâ Data synchronization completed successfully!', 'success');
                log(outputId, 'Total execution time: 4210ms', 'info');
                log(outputId, 'Total records processed: 10 posts', 'success');
                log(outputId, 'Successful API calls: 8/8', 'success');
                log(outputId, 'Failed requests: 0', 'info');
            } catch (error) {
                log(outputId, `Workflow failed: ${error.message}`, 'error');
            }
        }

        // Example 02: Microservice Orchestration
        async function runExample02(outputId) {
            log(outputId, 'üöÄ Starting Microservice Orchestration', 'info');
            log(outputId, 'Workflow ID: order-processing', 'info');
            log(outputId, 'Order ID: ORD-2024-001', 'info');
            log(outputId, 'Mode: Concurrent branch execution', 'info');
            
            try {
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                
                // Simulate concurrent branches
                const branches = [
                    { id: 'user-validation', name: 'User Validation Service', phases: ['validate-user'] },
                    { id: 'inventory', name: 'Inventory Service', phases: ['check-stock', 'reserve-items'] },
                    { id: 'payment', name: 'Payment Processing Service', phases: ['authorize', 'capture'] },
                    { id: 'notification', name: 'Notification Service', phases: ['send-email', 'send-sms'] }
                ];
                
                log(outputId, `Starting ${branches.length} service branches in parallel...`, 'info');
                await delay(300);
                
                for (const branch of branches) {
                    log(outputId, `üîÄ Branch: ${branch.name}`, 'phase');
                    log(outputId, `  Circuit Breaker: CLOSED (0 failures)`, 'info');
                    
                    for (const phase of branch.phases) {
                        log(outputId, `  ‚û§ Phase: ${phase}`, 'info');
                        await delay(400);
                        
                        try {
                            await simulateRequest(`/api/${branch.id}/${phase}`);
                            log(outputId, `  ‚úì ${phase} completed successfully`, 'success');
                            log(outputId, `  ‚öôÔ∏è  Circuit state: CLOSED`, 'info');
                        } catch (error) {
                            log(outputId, `  ‚úó ${phase} failed`, 'error');
                            log(outputId, `  ‚ö†Ô∏è  Circuit Breaker: OPENED`, 'warning');
                        }
                        await delay(200);
                    }
                    
                    log(outputId, `‚úì Branch "${branch.name}" completed`, 'success');
                    await delay(300);
                }
                
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üéâ Order ORD-2024-001 processed successfully!', 'success');
                log(outputId, 'All service branches: COMPLETED', 'success');
                log(outputId, 'Total branches: 4', 'info');
                log(outputId, 'Circuit breakers: All CLOSED', 'success');
            } catch (error) {
                log(outputId, `Workflow failed: ${error.message}`, 'error');
                log(outputId, 'Initiating rollback procedures...', 'warning');
            }
        }

        // Example 03: API Health Monitoring
        async function runExample03(outputId) {
            log(outputId, 'üöÄ Starting API Health Monitor', 'info');
            log(outputId, 'Monitoring interval: Every 30 seconds', 'info');
            log(outputId, 'Checking 3 critical services...', 'info');
            
            const services = [
                { name: 'User Authentication API', url: 'https://api.example.com/auth', sla: 200 },
                { name: 'Payment Gateway', url: 'https://api.example.com/payments', sla: 500 },
                { name: 'Order Management System', url: 'https://api.example.com/orders', sla: 1000 }
            ];
            
            log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
            
            for (const service of services) {
                log(outputId, `Checking ${service.name}...`, 'info');
                log(outputId, `  Endpoint: ${service.url}/health`, 'info');
                const startTime = Date.now();
                
                try {
                    await simulateRequest(`/health`);
                    const responseTime = Math.floor(Math.random() * service.sla * 0.8); // Simulate good response
                    const slaCompliant = responseTime <= service.sla;
                    
                    if (slaCompliant) {
                        log(outputId, `‚úì ${service.name}: HEALTHY`, 'success');
                        log(outputId, `  Response time: ${responseTime}ms (SLA: ${service.sla}ms)`, 'success');
                        log(outputId, `  Status: ‚úì Within SLA`, 'success');
                    } else {
                        log(outputId, `‚ö†Ô∏è  ${service.name}: SLA BREACH`, 'warning');
                        log(outputId, `  Response time: ${responseTime}ms > ${service.sla}ms`, 'warning');
                    }
                    
                    log(outputId, `  Circuit Breaker: CLOSED`, 'info');
                    log(outputId, `  Consecutive Failures: 0/3`, 'info');
                } catch (error) {
                    log(outputId, `‚úó ${service.name}: UNHEALTHY`, 'error');
                    log(outputId, `  Error: Connection timeout`, 'error');
                    log(outputId, `  Circuit Breaker: OPEN (Cooling down)`, 'warning');
                }
                
                await delay(500);
            }
            
            log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
            log(outputId, '‚úì Health check cycle completed', 'success');
            log(outputId, 'Healthy services: 3/3', 'success');
            log(outputId, 'SLA compliance: 100%', 'success');
        }

        // Example 04: Batch Image Processing
        async function runExample04(outputId) {
            log(outputId, 'üöÄ Starting Batch Image Processing', 'info');
            
            const images = [
                { id: 'IMG001', priority: 'high', icon: 'üî¥' },
                { id: 'IMG002', priority: 'high', icon: 'üî¥' },
                { id: 'IMG003', priority: 'normal', icon: 'üü°' },
                { id: 'IMG004', priority: 'normal', icon: 'üü°' },
                { id: 'IMG005', priority: 'normal', icon: 'üü°' },
                { id: 'IMG006', priority: 'normal', icon: 'üü°' },
                { id: 'IMG007', priority: 'normal', icon: 'üü°' },
                { id: 'IMG008', priority: 'low', icon: 'üü¢' },
                { id: 'IMG009', priority: 'low', icon: 'üü¢' },
                { id: 'IMG010', priority: 'low', icon: 'üü¢' }
            ];
            
            log(outputId, `Processing ${images.length} images...`, 'info');
            log(outputId, 'Concurrency limit: 5', 'info');
            log(outputId, 'Rate limit: 100 requests/minute', 'info');
            log(outputId, 'Priority order: üî¥ High ‚Üí üü° Normal ‚Üí üü¢ Low', 'info');
            
            log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
            
            let processed = 0;
            let successful = 0;
            let failed = 0;
            
            for (const img of images) {
                try {
                    log(outputId, `${img.icon} Processing ${img.id} (${img.priority} priority)...`, 'info');
                    await simulateRequest('/process-image', { mockData: { imageId: img.id } });
                    processed++;
                    successful++;
                    const progress = ((processed / images.length) * 100).toFixed(0);
                    log(outputId, `‚úì ${img.id} completed - Progress: ${progress}%`, 'success');
                    await delay(300);
                } catch (error) {
                    processed++;
                    failed++;
                    log(outputId, `‚úó Failed ${img.id}`, 'error');
                }
            }
            
            log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
            log(outputId, 'üéâ Batch processing complete!', 'success');
            log(outputId, `Total: ${images.length}`, 'info');
            log(outputId, `Successful: ${successful}`, 'success');
            log(outputId, `Failed: ${failed}`, failed > 0 ? 'warning' : 'info');
            log(outputId, 'Processing time: ~3.5s', 'info');
        }

        // Example 05: Feature Flag Testing
        async function runExample05(outputId) {
            log(outputId, 'üöÄ Starting Chaos Engineering with Trial Mode', 'info');
            log(outputId, 'Testing API resilience under different failure scenarios', 'info');
            log(outputId, 'Using StableRequest trial mode for comparison', 'info');
            
            const scenarios = [
                { name: 'Scenario 1: Healthy Baseline', failureRate: 0.0, icon: '‚úÖ' },
                { name: 'Scenario 2: Intermittent Failures', failureRate: 0.3, icon: '‚ö†Ô∏è' },
                { name: 'Scenario 3: High Failure Rate', failureRate: 0.7, icon: 'üî¥' },
                { name: 'Scenario 4: Persistent Failures', failureRate: 0.5, icon: '‚ùå' },
                { name: 'Scenario 5: Complete Outage', failureRate: 1.0, icon: 'üíÄ' }
            ];
            
            log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
            
            for (const scenario of scenarios) {
                log(outputId, `${scenario.icon} ${scenario.name}`, 'phase');
                log(outputId, `  Simulated failure rate: ${(scenario.failureRate * 100)}%`, 'info');
                
                let attempts = 10;
                let successes = 0;
                let failures = 0;
                
                for (let i = 1; i <= attempts; i++) {
                    const willFail = Math.random() < scenario.failureRate;
                    if (willFail) {
                        failures++;
                        log(outputId, `  Attempt ${i}/10: ‚úó FAILED (simulated error)`, 'error');
                    } else {
                        successes++;
                        log(outputId, `  Attempt ${i}/10: ‚úì SUCCESS`, 'success');
                    }
                    await delay(150);
                }
                
                const actualRate = (successes / attempts * 100).toFixed(0);
                log(outputId, `  Result: ${successes} successes, ${failures} failures`, 'info');
                log(outputId, `‚úì ${scenario.name}: ${actualRate}% success rate`, successes > failures ? 'success' : 'warning');
                await delay(400);
            }
            
            log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
            log(outputId, 'üéâ A/B testing completed!', 'success');
        }

        // Example 06: State Persistence Workflow
        async function runExample06(outputId) {
            log(outputId, 'üöÄ Starting Distributed Workflow with State Persistence', 'info');
            log(outputId, 'Workflow ID: data-migration-2024', 'info');
            log(outputId, 'Using Redis-based state persistence', 'info');
            log(outputId, 'Lock: Distributed lock acquired for 5 minutes', 'info');
            
            log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
            
            try {
                // Phase 1: Extract
                log(outputId, 'üìç Phase 1: Extract source data', 'phase');
                await delay(500);
                log(outputId, 'üì• Connecting to source database...', 'info');
                await delay(400);
                log(outputId, 'Fetching user records from legacy system...', 'info');
                await delay(600);
                log(outputId, '‚úì Extracted 1000 records from source', 'success');
                log(outputId, 'üíæ State key: workflow:data-migration-2024:main:extract-data', 'info');
                log(outputId, 'üíæ Stored state snapshot (TTL: 3600s)', 'info');
                log(outputId, 'Progress: 33%', 'info');
                await delay(300);
                
                // Phase 2: Transform
                log(outputId, 'üìç Phase 2: Transform data', 'phase');
                await delay(500);
                log(outputId, 'üîÑ Loading previous state from Redis...', 'info');
                await delay(400);
                log(outputId, '‚úì Loaded: 1000 records from extract phase', 'info');
                log(outputId, 'Normalizing data formats...', 'info');
                await delay(500);
                log(outputId, 'Enriching with metadata...', 'info');
                await delay(400);
                log(outputId, '‚úì Transformed 1000 records successfully', 'success');
                log(outputId, 'üíæ State key: workflow:data-migration-2024:main:transform-data', 'info');
                log(outputId, 'üíæ Stored state snapshot (TTL: 3600s)', 'info');
                log(outputId, 'Progress: 66%', 'info');
                await delay(300);
                
                // Phase 3: Validate
                log(outputId, 'üìç Phase 3: Validate data', 'phase');
                await delay(500);
                log(outputId, 'üîÑ Loading previous state from Redis...', 'info');
                await delay(400);
                log(outputId, '‚úì Loaded: 1000 transformed records', 'info');
                log(outputId, 'Running data quality rules...', 'info');
                await delay(500);
                log(outputId, 'Checking referential integrity...', 'info');
                await delay(400);
                log(outputId, '‚úì All 1000 records passed validation', 'success');
                log(outputId, 'üíæ State key: workflow:data-migration-2024:main:validate-data', 'info');
                log(outputId, 'üíæ Stored final state (TTL: 7200s)', 'info');
                log(outputId, 'Progress: 100%', 'success');
                await delay(300);
                
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üéâ Workflow completed successfully!', 'success');
                log(outputId, 'Total records processed: 1000', 'success');
                log(outputId, 'üíæ All checkpoints saved to Redis', 'info');
                log(outputId, 'üîí Distributed lock released', 'info');
                log(outputId, 'Workflow can be resumed from any phase', 'info');
            } catch (error) {
                log(outputId, `Workflow interrupted: ${error.message}`, 'error');
                log(outputId, 'üíæ State checkpoint saved - can resume from last phase', 'warning');
                log(outputId, 'üîí Lock will auto-expire in 5 minutes', 'warning');
            }
        }

        // Example 07: Real-Time Metrics Monitoring
        async function runExample07(outputId) {
            log(outputId, 'üöÄ Starting Real-Time Metrics Monitoring', 'info');
            log(outputId, 'Workflow ID: metrics-monitoring-demo', 'info');
            log(outputId, 'Architecture: Multi-branch with comprehensive metrics', 'info');
            
            try {
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                
                // Infrastructure setup
                log(outputId, '‚öôÔ∏è  Infrastructure Setup:', 'phase');
                await delay(200);
                log(outputId, '  Circuit Breaker: CLOSED (50% threshold, 10s recovery)', 'info');
                log(outputId, '  Cache: Enabled (30s TTL, 200 max size)', 'info');
                log(outputId, '  Rate Limiter: 50 req/10s', 'info');
                log(outputId, '  Concurrency Limiter: 10 concurrent', 'info');
                await delay(300);
                
                // Branch 1: Data Collection
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üåø Branch 1: data-collection', 'phase');
                
                log(outputId, '  Phase: fetch-users (3 requests)', 'info');
                await delay(500);
                log(outputId, '    ‚úì users-list completed (250ms)', 'success');
                log(outputId, '    ‚úì user-1 completed (180ms)', 'success');
                log(outputId, '    ‚úì user-2 completed (195ms)', 'success');
                log(outputId, '  üìä Phase completed: 3/3 successful (625ms total)', 'success');
                await delay(300);
                
                log(outputId, '  Phase: fetch-posts (15 requests)', 'info');
                await delay(800);
                log(outputId, '    ‚úì 15 posts fetched concurrently', 'success');
                log(outputId, '    üíæ Cache: 0 hits, 15 misses (first run)', 'info');
                log(outputId, '  üìä Phase completed: 15/15 successful (1320ms total)', 'success');
                await delay(300);
                
                log(outputId, '  ‚úÖ Branch completed: 18/18 requests successful (1945ms)', 'success');
                
                // Branch 2: Data Processing (concurrent)
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üåø Branch 2: data-processing (concurrent)', 'phase');
                
                log(outputId, '  Phase: fetch-comments (10 requests)', 'info');
                await delay(700);
                log(outputId, '    ‚úì 10 comment groups fetched', 'success');
                log(outputId, '    üö¶ Rate limiter: 28/50 tokens used', 'info');
                log(outputId, '  üìä Phase completed: 10/10 successful (980ms total)', 'success');
                await delay(300);
                
                log(outputId, '  ‚úÖ Branch completed: 10/10 requests successful (980ms)', 'success');
                
                // Branch 3: Data Enrichment (concurrent)
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üåø Branch 3: data-enrichment (concurrent)', 'phase');
                
                log(outputId, '  Phase: fetch-albums (8 requests)', 'info');
                await delay(600);
                log(outputId, '    ‚úì 8 albums fetched concurrently', 'success');
                log(outputId, '    üî¢ Concurrency: 8/10 slots used (80% utilization)', 'info');
                log(outputId, '  üìä Phase completed: 8/8 successful (1050ms total)', 'success');
                await delay(300);
                
                log(outputId, '  Phase: fetch-photos (5 requests)', 'info');
                await delay(500);
                log(outputId, '    ‚úì 5 photo sets fetched', 'success');
                log(outputId, '  üìä Phase completed: 5/5 successful (530ms total)', 'success');
                await delay(300);
                
                log(outputId, '  ‚úÖ Branch completed: 13/13 requests successful (1580ms)', 'success');
                
                // Metrics extraction
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üîç Extracting Comprehensive Metrics...', 'phase');
                await delay(500);
                
                // Workflow metrics
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üìà WORKFLOW METRICS:', 'phase');
                await delay(200);
                log(outputId, '  Total Execution Time: 2350ms', 'info');
                log(outputId, '  Total Requests: 41 (41 success, 0 failed)', 'success');
                log(outputId, '  Success Rate: 100.00%', 'success');
                log(outputId, '  Throughput: 17.45 req/sec', 'info');
                log(outputId, '  Branches: 3/3 completed (100% success)', 'success');
                log(outputId, '  Phases: 5/5 completed', 'success');
                await delay(300);
                
                // Infrastructure metrics
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, '‚öôÔ∏è  INFRASTRUCTURE METRICS:', 'phase');
                await delay(200);
                
                log(outputId, '  üîå Circuit Breaker:', 'info');
                log(outputId, '    State: CLOSED ‚úÖ', 'success');
                log(outputId, '    Health: Healthy', 'success');
                log(outputId, '    Failure Rate: 0.00%', 'success');
                log(outputId, '    Total Requests: 41', 'info');
                await delay(200);
                
                log(outputId, '  üíæ Cache:', 'info');
                log(outputId, '    Status: Enabled', 'success');
                log(outputId, '    Hit Rate: 0.00% (first run)', 'info');
                log(outputId, '    Entries: 41/200 (20.5% utilized)', 'info');
                log(outputId, '    Network Requests Saved: 0', 'info');
                await delay(200);
                
                log(outputId, '  üö¶ Rate Limiter:', 'info');
                log(outputId, '    Limit: 50 req/10s', 'info');
                log(outputId, '    Available Tokens: 9', 'info');
                log(outputId, '    Throttled: 0 requests (0.00%)', 'success');
                log(outputId, '    Current Rate: 17.45 req/sec', 'info');
                log(outputId, '    Utilization: 82.00%', 'info');
                await delay(200);
                
                log(outputId, '  üî¢ Concurrency Limiter:', 'info');
                log(outputId, '    Limit: 10 concurrent', 'info');
                log(outputId, '    Peak Concurrency: 10 (100% utilized)', 'info');
                log(outputId, '    Avg Queue Wait: 125ms', 'info');
                log(outputId, '    Success Rate: 100.00%', 'success');
                await delay(300);
                
                // Alerts and recommendations
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üö® ALERTS & RECOMMENDATIONS:', 'phase');
                await delay(300);
                log(outputId, '  ‚ö†Ô∏è  WARNING: Throughput below target', 'warning');
                log(outputId, '     Metric: throughput = 17.45 req/sec (threshold: 50)', 'warning');
                log(outputId, '     üí° Recommendation: Consider increasing concurrency limits', 'info');
                await delay(200);
                log(outputId, '  ‚ÑπÔ∏è  INFO: Low cache hit rate', 'info');
                log(outputId, '     Metric: hitRate = 0.00% (threshold: 30)', 'info');
                log(outputId, '     üí° Recommendation: Normal for first run - cache will warm up', 'info');
                await delay(300);
                
                // Health score
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üè• SYSTEM HEALTH SCORE:', 'phase');
                await delay(200);
                log(outputId, '  üü¢ Overall Health Score: 90/100 (EXCELLENT)', 'success');
                log(outputId, '  ‚Ä¢ 90-100: Excellent - System performing optimally ‚úÖ', 'info');
                await delay(300);
                
                // Summary
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, 'üìä PERFORMANCE SUMMARY:', 'phase');
                await delay(200);
                log(outputId, '  ‚è±Ô∏è  Total Workflow Time: 2350ms', 'info');
                log(outputId, '  üìà Average Phase Time: 1091ms', 'info');
                log(outputId, '  üî¢ Total Requests: 41', 'info');
                log(outputId, '  ‚úÖ Successful Requests: 41 (100%)', 'success');
                log(outputId, '  ‚ùå Failed Requests: 0', 'success');
                log(outputId, '  üåø Branches: 3 (all concurrent)', 'info');
                log(outputId, '  üíæ Cache Efficiency: Building (0% on first run)', 'info');
                await delay(300);
                
                log(outputId, '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', 'info');
                log(outputId, '‚úÖ Metrics monitoring example completed successfully!', 'success');
                log(outputId, 'All metrics extracted and analyzed', 'success');
                log(outputId, 'System health: EXCELLENT', 'success');
                
            } catch (error) {
                log(outputId, `Monitoring failed: ${error.message}`, 'error');
            }
        }

        // Event handlers
        document.querySelectorAll('.run-example-btn').forEach(button => {
            button.addEventListener('click', async function() {
                const exampleId = this.getAttribute('data-example');
                const output = document.getElementById(`output-${exampleId}`);
                const clearBtn = document.querySelector(`.clear-output-btn[data-example="${exampleId}"]`);
                
                // Show output and clear button
                output.style.display = 'block';
                output.innerHTML = '';
                clearBtn.style.display = 'inline-block';
                
                // Disable button during execution
                this.disabled = true;
                this.textContent = '‚è≥ Running...';
                
                // Run the appropriate example
                try {
                    switch(exampleId) {
                        case '01': await runExample01(exampleId); break;
                        case '02': await runExample02(exampleId); break;
                        case '03': await runExample03(exampleId); break;
                        case '04': await runExample04(exampleId); break;
                        case '05': await runExample05(exampleId); break;
                        case '06': await runExample06(exampleId); break;
                        case '07': await runExample07(exampleId); break;
                    }
                } catch (error) {
                    log(exampleId, `Unexpected error: ${error.message}`, 'error');
                }
                
                // Re-enable button
                this.disabled = false;
                this.textContent = '‚ñ∂ Run Example';
            });
        });

        // Clear output handlers
        document.querySelectorAll('.clear-output-btn').forEach(button => {
            button.addEventListener('click', function() {
                const outputId = this.getAttribute('data-output');
                const output = document.getElementById(outputId);
                output.innerHTML = '';
                output.style.display = 'none';
                this.style.display = 'none';
            });
        });
        
        // Add copy buttons to all code blocks
        document.querySelectorAll('pre code').forEach((codeBlock) => {
            const pre = codeBlock.parentElement;
            const button = document.createElement('button');
            button.className = 'copy-button';
            button.textContent = 'Copy';
            button.setAttribute('aria-label', 'Copy code to clipboard');
            
            button.addEventListener('click', async () => {
                const code = codeBlock.textContent;
                try {
                    await navigator.clipboard.writeText(code);
                    button.textContent = 'Copied!';
                    button.classList.add('copied');
                    setTimeout(() => {
                        button.textContent = 'Copy';
                        button.classList.remove('copied');
                    }, 2000);
                } catch (err) {
                    button.textContent = 'Failed';
                    setTimeout(() => {
                        button.textContent = 'Copy';
                    }, 2000);
                }
            });
            
            pre.style.position = 'relative';
            pre.appendChild(button);
        });
        
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({ behavior: 'smooth', block: 'start' });
                }
            });
        });
    </script>
</body>
</html>
